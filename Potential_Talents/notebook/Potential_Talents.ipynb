{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b7683f",
   "metadata": {},
   "source": [
    "Importing NLP model packages and general packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59bf5c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\GEOFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GEOFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a0228",
   "metadata": {},
   "source": [
    "Setup your directory to that of the folder containing the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605c72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/GEOFF/OneDrive/Documents/Apziva/Potential_Talents'\n",
    "os.chdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6d388",
   "metadata": {},
   "source": [
    "Importing the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002e5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data imported\n",
      "Column 'id' and duplicate rows were removed\n",
      "\n",
      "The dataframe columns and their types are:\n",
      " {'job_title': <class 'str'>, 'location': <class 'str'>, 'connection': <class 'str'>, 'fit': <class 'str'>}\n",
      "\n",
      "The dataframe shape is (53, 4)\n"
     ]
    }
   ],
   "source": [
    "## Import the raw data into a dataframe\n",
    "data_path = \"data/raw/\"\n",
    "dataframe = pd.read_csv(data_path + \"potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "print('\\nData imported')\n",
    "dataframe.drop_duplicates(inplace = True, subset = ['job_title', 'location', 'connection'])\n",
    "dataframe.reset_index(drop = True, inplace = True)\n",
    "## Remove a non informative feature\n",
    "dataframe.drop(inplace = True, labels=['id'], axis = 1)\n",
    "print('''Column 'id' and duplicate rows were removed''')\n",
    "##\n",
    "\n",
    "## Display basic information about the dataframe\n",
    "types = [type(c) for c in dataframe.columns]\n",
    "print('\\nThe dataframe columns and their types are:\\n', dict(zip(dataframe.columns, types)))\n",
    "print(f\"\\nThe dataframe shape is {dataframe.shape}\")\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592448a",
   "metadata": {},
   "source": [
    "Pre-processing of the job_title and location strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7ef021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first job title:\n",
      " 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "The first job title is pre-processed as:\n",
      " bauer colleg busi graduat magna cum laud aspir human resourc profession\n"
     ]
    }
   ],
   "source": [
    "# All the job titles, locations and number of connections will be pre-processed before encoding\n",
    "jobs = list(dataframe['job_title'])\n",
    "locations = list(dataframe['location'])\n",
    "connections = list(dataframe['connection'])\n",
    "processed_jobs = []\n",
    "processed_locations = []\n",
    "processed_connections = np.zeros(len(connections))\n",
    "\n",
    "def process_string(txt):\n",
    "    # Returns a list of processed words extracted from txt string\n",
    "    words = [] # Will contain the words in the txt string\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # Next, separate the words\n",
    "    seps = [' '] + list(string.punctuation)\n",
    "    default_sep = seps[0]\n",
    "    for sep in seps[1:]:\n",
    "        txt = txt.replace(sep, default_sep)\n",
    "    word_list = [i.strip().lower() for i in txt.split(default_sep)]\n",
    "    #\n",
    "    \n",
    "    def not_a_number(word):\n",
    "        # Returns if the word is or contains a number\n",
    "        for i in word:\n",
    "            if i in string.digits:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Remove stop words from the list and stems\n",
    "    for word in word_list:\n",
    "        if word == 'hr':\n",
    "            words.append('human'); words.append('resourc')\n",
    "        elif (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation and\n",
    "                    len(word) > 1 and not_a_number(word)):  # remove punctuation\n",
    "                stem_word = stemmer.stem(word)  # stemming word\n",
    "                words.append(stem_word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "for job in jobs:\n",
    "    processed_jobs.append(process_string(job))\n",
    "for loc in locations:\n",
    "    processed_locations.append(process_string(loc))\n",
    "for i, con in enumerate(connections):\n",
    "    if con.strip() == '500+':\n",
    "        processed_connections[i] = 1\n",
    "    elif con.strip() == '0':\n",
    "        processed_connections[i] = 0\n",
    "    else:\n",
    "        processed_connections[i] = np.log(int(con))/np.log(500)\n",
    "\n",
    "processed = dict( [ (i, (processed_jobs[i], processed_locations[i], processed_connections[i], 0) ) for i in range(len(connections)) ] )\n",
    "processed_data = pd.DataFrame.from_dict(processed, orient = 'index', columns = ['job_title', 'location', 'log_connections', 'fit'])\n",
    "processed_example = processed_data['job_title'][0]\n",
    "print('The first job title:\\n', dataframe['job_title'][0])\n",
    "print('The first job title is pre-processed as:\\n', processed_example)\n",
    "## Now all the data has been pre-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813981a8",
   "metadata": {},
   "source": [
    "Encoding of the job_title and location string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820cf5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first job title is encoded as:\n",
      " [ 2.29601394e-02  5.29033272e-03  1.23129478e-02 -1.52566116e-02\n",
      "  2.62993630e-02  2.87623107e-02  6.21659271e-02  1.25092585e-02\n",
      "  2.13480592e-02 -1.14011122e-02  5.59398942e-02 -3.47674564e-02\n",
      "  2.57837474e-02  2.77773067e-02  4.16573100e-02 -2.98467092e-03\n",
      " -3.81730590e-03  1.44228656e-02 -3.12444046e-02 -2.88489778e-02\n",
      " -6.44241050e-02  1.40412776e-02 -3.37941870e-02  4.46511284e-02\n",
      "  6.03639036e-02 -3.46612409e-02  4.96585965e-02  9.08143818e-03\n",
      "  1.52817573e-02  3.07963211e-02  6.50279447e-02  1.14242788e-02\n",
      " -3.43585461e-02 -1.24222990e-02  1.72793864e-06 -1.12664634e-02\n",
      " -2.18778625e-02 -1.94274206e-02 -4.32560779e-02 -4.73480187e-02\n",
      "  3.41828205e-02  7.90508091e-02 -2.95838807e-02 -4.17338498e-03\n",
      " -4.60210554e-02  8.49153548e-02  2.01138984e-02  4.81949002e-02\n",
      " -6.39029592e-02  3.75806564e-03  7.48163136e-03 -6.67717531e-02\n",
      " -1.49225164e-02 -5.89881837e-02 -3.35062109e-02 -6.51961863e-02\n",
      "  2.76170182e-03 -4.90266308e-02  8.01380351e-02  8.47537071e-02\n",
      " -1.42194778e-02  4.33760248e-02 -4.65899594e-02 -3.59697863e-02\n",
      "  1.70000494e-02  2.03901101e-02  1.47823617e-02 -2.97269840e-02\n",
      "  3.95142660e-02 -1.91631950e-02  5.33698685e-02 -6.46532699e-03\n",
      "  1.45517420e-02  9.70911607e-02  3.99283394e-02 -3.88686429e-03\n",
      "  5.73885161e-03  9.46839619e-03 -5.18020988e-02 -3.61465104e-02\n",
      "  1.58690121e-02  1.75963398e-02 -4.35864739e-02  6.79060221e-02\n",
      "  6.22542277e-02  1.34559860e-02 -1.33937644e-02 -4.39637108e-03\n",
      "  7.24888146e-02 -2.94530392e-02  7.65250027e-02 -8.79073329e-03\n",
      "  2.99943071e-02  8.86751339e-02 -2.54028365e-02 -5.50412387e-02\n",
      "  2.21636649e-02 -5.19853979e-02  1.58644971e-02 -3.76527496e-02\n",
      " -4.01238054e-02 -2.79650907e-03  3.49917971e-02  5.10803498e-02\n",
      " -1.97019242e-03  6.31496757e-02  1.33869154e-02  1.70101486e-02\n",
      " -3.30087617e-02  4.46960628e-02 -4.19436842e-02  1.61375478e-02\n",
      " -3.26607153e-02  8.21755454e-03 -1.10830851e-02  6.58257455e-02\n",
      " -8.99338573e-02 -3.11219171e-02  8.73754080e-03  2.21055076e-02\n",
      " -4.06464636e-02  2.08451040e-02 -2.50281617e-02  3.89209725e-02\n",
      " -1.10016475e-02 -1.66658796e-02 -3.98497470e-02 -2.65190955e-02\n",
      " -3.29460688e-02  2.23189425e-02  2.72548739e-02  1.64963920e-02\n",
      " -5.02278453e-05 -2.80016176e-02 -3.75751569e-03 -4.68271077e-02\n",
      " -3.16462368e-02  1.20915109e-02  1.54102817e-02 -2.18109600e-02\n",
      " -1.87725648e-02 -5.08218780e-02 -6.78257667e-04  2.64473017e-02\n",
      "  6.07827166e-03  1.82515830e-02 -2.97609437e-03 -7.64439180e-02\n",
      "  7.39767868e-03 -2.40730587e-03 -5.62066585e-03 -2.31680106e-02\n",
      "  2.25285459e-02 -8.57619382e-03  6.94547445e-02  3.87463681e-02\n",
      "  2.91544385e-02 -4.22381200e-02 -4.75495681e-02  2.85343621e-02\n",
      " -4.28931117e-02 -7.03368429e-03  5.37017025e-02 -5.80515200e-03\n",
      " -8.46172310e-03 -6.43582791e-02  3.17029171e-02  1.01571088e-03\n",
      " -2.29660701e-02  2.29111779e-02 -2.05125916e-03  2.15539485e-02\n",
      " -2.62818299e-02  7.99830556e-02 -1.95554886e-02  5.83517291e-02\n",
      "  3.60521525e-02  8.44678655e-03 -6.07757233e-02 -2.47924551e-02\n",
      "  6.68412670e-02 -8.08035508e-02 -3.94347170e-03 -5.11123519e-03\n",
      "  4.08773981e-02  6.41751336e-03 -3.18884403e-02  1.81930549e-02\n",
      " -8.87851696e-03 -1.78859998e-02  3.17206047e-02  1.67483073e-02\n",
      " -7.14527369e-02  1.11843869e-02 -5.65514667e-03 -2.37097014e-02\n",
      " -1.16873216e-02 -5.14845327e-02 -1.75261609e-02 -5.80647625e-02\n",
      " -6.19642949e-03 -7.71140307e-03  4.28951494e-02  4.00537662e-02\n",
      "  4.38188091e-02  3.49312671e-03  4.40358073e-02 -2.86409501e-02\n",
      " -1.21417167e-02  2.68934220e-02  5.37067512e-03 -3.49476212e-03\n",
      "  5.74416295e-02  7.38205621e-04 -7.17773708e-03 -2.42890813e-03\n",
      " -1.59321483e-02  3.49726640e-02 -4.63706106e-02  6.26141876e-02\n",
      "  6.22804090e-03  6.25974238e-02 -5.59032075e-02 -1.65388361e-02\n",
      " -5.63462190e-02 -1.13696232e-02  1.78438034e-02 -2.32999120e-02\n",
      " -6.89455355e-03  2.90679391e-02  1.45021835e-02  2.13546073e-03\n",
      " -1.42698502e-02 -2.42522415e-02 -2.18776111e-02  2.81404946e-02\n",
      "  3.88731956e-02  2.04424690e-02 -1.30580859e-02 -3.75520028e-02\n",
      " -5.98417222e-02 -3.31996032e-03  4.88386489e-02 -1.83953706e-03\n",
      "  3.66999730e-02 -4.14713146e-03  9.90104377e-02  2.73861568e-02\n",
      "  4.05586995e-02 -7.07234303e-03  3.34298946e-02 -2.69757751e-02\n",
      " -1.50736049e-02  4.58704904e-02  3.49274650e-02 -3.50408480e-02\n",
      " -1.13310233e-01  2.34292392e-02 -4.24579456e-02 -2.06751395e-02\n",
      "  3.44376862e-02 -4.41217981e-02 -1.78415775e-02  7.19036162e-03\n",
      "  5.00421934e-02  3.62478616e-03  2.61457097e-02 -3.46397026e-03\n",
      " -4.61573303e-02  6.87504606e-03 -4.05082777e-02 -1.20267505e-02\n",
      "  1.76075473e-02 -5.85276913e-03 -3.26705794e-03 -3.29609774e-02\n",
      " -2.79756123e-03 -1.82891842e-02 -6.64846078e-02  6.04124693e-03\n",
      "  9.71010327e-03  6.46743625e-02 -3.90104167e-02 -5.08580124e-03\n",
      " -8.18921253e-03  1.57614257e-02  1.00616537e-01 -6.21150658e-02\n",
      " -1.49094481e-02  3.35890912e-02 -1.44433891e-02  3.57772503e-03\n",
      " -1.14023604e-03 -3.00080106e-02 -3.67277935e-02  4.27987501e-02\n",
      "  6.06302470e-02  8.55752081e-02 -1.78789638e-03  1.69584099e-02\n",
      " -3.78953964e-02  1.17810108e-02  1.44314812e-02 -3.46475397e-03\n",
      " -2.08468735e-02  4.96579222e-02  3.31133162e-03  2.45426167e-02\n",
      " -3.44510935e-02 -9.80186835e-02 -5.16964421e-02  6.69000810e-03\n",
      "  6.66503534e-02  7.13544665e-03  6.88908296e-03 -2.99171023e-02\n",
      " -6.50642142e-02 -4.25815135e-02  3.13517428e-03  2.56519597e-02\n",
      "  1.49194608e-02  5.49061485e-02 -4.21700999e-02 -1.69923645e-03\n",
      " -1.07055996e-03 -3.08777653e-02 -5.87883480e-02  1.41561152e-02\n",
      "  1.96470134e-02 -4.98849675e-02  1.57111306e-02 -1.61655936e-02\n",
      " -5.21660671e-02 -2.65791211e-02  1.73006672e-02 -3.49779092e-02\n",
      " -5.43148220e-02  1.19869169e-02  1.21980160e-02 -9.73682757e-03\n",
      " -4.71473262e-02 -3.85332368e-02 -5.87277710e-02  3.66678350e-02\n",
      "  4.46250848e-02  2.03981604e-02  3.93417701e-02 -6.05166424e-03\n",
      " -1.28262699e-01 -3.31170000e-02  3.28924730e-02  3.28956023e-02\n",
      " -5.11221103e-02  1.08578196e-02 -3.80115733e-02 -2.54238322e-02\n",
      "  3.00567355e-02  1.45981275e-02  6.99019700e-04  1.09246671e-02\n",
      " -2.05837078e-02 -7.34406663e-03 -3.19124833e-02 -2.97370064e-03\n",
      "  3.90052907e-02 -2.79300939e-02  3.94718908e-02 -4.69226111e-03\n",
      " -6.39386126e-04 -4.89271283e-02  4.36639041e-02  1.32750999e-03\n",
      " -3.64435837e-02  4.77954559e-02 -4.71114777e-02 -3.93876955e-02\n",
      " -1.38684604e-02  1.27751492e-02 -5.27590737e-02 -3.51620349e-03\n",
      "  4.06500474e-02  6.70752972e-02  9.26308185e-02 -2.03274712e-02\n",
      "  2.13745255e-02 -4.73595075e-02 -1.13736512e-02 -2.17554513e-02\n",
      "  2.87726545e-03  3.87967750e-02  2.45836452e-02 -1.44006899e-02\n",
      " -3.47390398e-02 -1.93073675e-02 -3.75679694e-02  2.61197612e-02\n",
      " -1.87107138e-02  1.40319578e-02 -2.36620791e-02  4.64507192e-02\n",
      "  1.79660507e-02  5.83515689e-03 -1.67425815e-02  2.09706109e-02\n",
      " -1.27814747e-02 -1.53341498e-02 -7.57862302e-03  2.25091241e-02\n",
      " -7.24339336e-02 -6.01300877e-03  6.75984798e-03  7.82392640e-03\n",
      " -1.89574882e-02  1.33129805e-02  1.92066655e-02 -6.85426369e-02\n",
      " -2.07429547e-02 -3.96058969e-02  2.93684267e-02 -6.01523034e-02\n",
      "  3.30213606e-02  4.68660779e-02  1.49509590e-02 -1.18479673e-02\n",
      "  2.06725467e-02 -3.45524885e-02  3.22823413e-02  3.23157050e-02\n",
      " -9.30072647e-03 -3.47535089e-02  1.17920199e-02  9.48455464e-03\n",
      " -2.08671819e-02  4.69473638e-02  1.65807363e-02 -4.56068255e-02\n",
      "  1.46856131e-02 -5.52838594e-02 -5.16788103e-02  4.52977642e-02\n",
      " -2.60986900e-03  4.18816544e-02  7.14396089e-02 -4.92471643e-03\n",
      " -1.35167013e-03  3.81051190e-03  1.06914639e-02 -4.76505123e-02\n",
      " -3.68138053e-03 -6.24419935e-03  6.11096472e-02 -3.00202835e-02\n",
      " -7.16316793e-03 -2.50276434e-03 -1.26817022e-02 -4.99513932e-02\n",
      " -4.43849862e-02  2.72261910e-02 -9.84244142e-03 -9.40613332e-04\n",
      "  2.74466071e-02  4.85310890e-02 -3.13706622e-02 -8.07919260e-03\n",
      " -5.15656620e-02  7.57271750e-03 -2.22802558e-03 -1.00526549e-02\n",
      "  4.79652323e-02 -2.72728782e-02 -1.83585398e-02 -5.76741574e-03\n",
      " -2.67860405e-02  2.37090643e-02  8.44529178e-03 -9.22273099e-03\n",
      " -2.76301391e-02  4.99942005e-02  2.12623738e-02  1.22321062e-02\n",
      "  4.08637002e-02 -4.56865951e-02 -1.56349819e-02 -2.71952748e-02\n",
      " -7.86701217e-03 -6.07008301e-03  3.30721363e-02  1.33200327e-03\n",
      "  3.13297436e-02 -2.19467524e-02  4.87268455e-02 -1.60273071e-02\n",
      " -1.85327940e-02 -1.15587652e-01  2.39158864e-03  1.30708441e-02\n",
      "  1.15037826e-03  7.08192289e-02 -2.03212965e-02  4.40755375e-02\n",
      "  1.52533995e-02  2.18634456e-02  2.85785645e-02  7.03897187e-03\n",
      "  2.81453580e-02  5.44396713e-02  1.17321387e-02  2.08396781e-02\n",
      " -5.64351771e-03  3.21279056e-02  3.08801383e-02  1.83003247e-02\n",
      " -3.92855555e-02 -2.46834978e-02 -1.66913122e-02  3.30927111e-02\n",
      " -4.74801324e-02  2.76111718e-02 -1.39856180e-02  1.80121791e-02\n",
      "  3.28865424e-02 -4.66518998e-02  1.21202543e-02 -7.23355636e-02\n",
      "  8.20100866e-03 -1.31755657e-02  1.24673108e-02  2.05221400e-02\n",
      "  1.78609136e-02  2.18727253e-03 -1.46439346e-02 -3.28949764e-02\n",
      " -6.68456359e-03  2.43935306e-02 -2.52379919e-04 -3.87359783e-02\n",
      "  2.54341643e-02  1.84936188e-02  3.72774564e-02  4.99139018e-02\n",
      " -2.36513522e-02 -2.74126921e-02  5.20327538e-02  1.96567830e-02\n",
      " -2.20709369e-02 -2.02134345e-02 -1.14364112e-02 -7.81650748e-03\n",
      "  1.54105248e-03  1.74289141e-02 -3.98259014e-02  8.94751698e-02\n",
      " -2.77603026e-02  1.60805527e-02  7.41507858e-03 -5.36216295e-33\n",
      "  3.17728966e-02 -3.83000635e-02  4.10444811e-02  4.78828102e-02\n",
      " -6.79680780e-02 -3.17952447e-02  2.67093703e-02  2.47285562e-03\n",
      " -7.37611353e-02 -1.28321666e-02 -3.74003835e-02  8.71355738e-03\n",
      "  2.37102509e-02  1.76277310e-02  4.60154414e-02  1.54351612e-04\n",
      " -1.70451943e-02  1.37334662e-02 -1.60641186e-02 -1.51343364e-02\n",
      " -4.15325239e-02  2.41592973e-02  5.46113700e-02 -4.09907708e-03\n",
      " -2.37342494e-04 -6.01571053e-02 -1.20388875e-02 -4.99337018e-02\n",
      "  3.18437740e-02 -2.23452840e-02  1.42884264e-02 -2.12042630e-02\n",
      "  2.57654004e-02  2.91972747e-03  4.31353673e-02  2.10982598e-02\n",
      " -4.43768166e-02 -2.32654624e-03 -8.80458974e-04  3.33526805e-02\n",
      " -3.59215364e-02 -2.86622178e-02  8.69523676e-04 -1.97787806e-02\n",
      " -2.92019267e-02 -2.32181475e-02  9.32592247e-03  2.95615681e-02\n",
      "  1.11219659e-02 -3.86539064e-02 -3.83554995e-02 -1.91502422e-02\n",
      " -3.71905193e-02  1.38046518e-02 -2.31302343e-03  7.50907417e-03\n",
      "  1.36909522e-02 -5.03063016e-03  8.58163461e-03 -2.27161087e-02\n",
      " -1.39014861e-02  4.72836941e-02 -1.53411413e-02 -5.42991608e-02\n",
      " -6.30176812e-02 -1.64720137e-02  5.79030886e-02  6.10883124e-02\n",
      "  2.83157174e-02 -8.38436335e-02  3.45281372e-03  5.97319752e-02\n",
      " -3.00759356e-02  2.38811560e-02 -3.88991609e-02 -5.32787070e-02\n",
      "  4.13778648e-02  4.67200903e-03  1.28177017e-01 -2.26050522e-03\n",
      " -7.16646314e-02 -1.34948380e-02  1.02403946e-02 -1.73588619e-02\n",
      "  1.21645685e-02 -4.18656804e-02  1.13047594e-02  6.10977672e-02\n",
      "  1.88753232e-02 -3.14763039e-02  5.25638089e-02  3.36632947e-03\n",
      " -1.90174598e-02 -2.15801504e-02  3.80040035e-02 -4.43155356e-02\n",
      "  3.58753875e-02 -4.33460623e-03 -1.07444339e-02  4.50190566e-02\n",
      " -5.60515001e-02  1.04656327e-03 -5.84894717e-02  9.73917022e-02\n",
      "  1.29157323e-02  1.37447100e-03  2.40416196e-03 -3.48447897e-02\n",
      "  9.51705594e-03 -2.03617681e-02  1.77873597e-02  1.39677161e-02\n",
      "  4.97589447e-02 -3.16695571e-02 -2.00072546e-02 -1.83119066e-03\n",
      "  2.11745799e-02 -4.36948575e-02  1.04456292e-02  5.60338981e-03\n",
      "  2.66039353e-02 -4.78466824e-02  5.05803227e-02 -1.31280618e-02\n",
      " -6.88548684e-02 -8.14770721e-03  3.88466604e-02 -1.17246332e-02\n",
      "  4.89305556e-02 -6.01325147e-02  3.62325571e-02 -5.50282821e-02\n",
      "  2.38929005e-07  1.02411611e-02  7.94727877e-02  6.20986393e-04\n",
      " -3.37252244e-02  6.82263495e-03 -4.99155708e-02  3.41182873e-02\n",
      "  3.24333012e-02  1.16631221e-02  4.00095358e-02  2.18456890e-02\n",
      " -4.29071151e-02 -1.09698744e-02 -4.96912934e-02 -5.96144646e-02\n",
      " -7.02973306e-02 -5.16481549e-02 -6.13132119e-02  8.76308233e-03\n",
      " -3.13144065e-02 -3.03639029e-03  7.01015722e-03  2.69594677e-02\n",
      " -1.58657264e-02 -2.84964275e-02 -2.72455476e-02 -8.85287952e-03\n",
      "  4.80500748e-03  4.34942506e-02  5.29538617e-02  1.10056242e-02\n",
      "  3.03946231e-02  2.07226779e-02  1.80409290e-02  1.87035706e-02\n",
      " -2.69741062e-02  1.04819946e-01  5.88555261e-02 -1.85376815e-02\n",
      "  4.71773557e-02 -2.65306123e-02  1.44710448e-02 -1.43511277e-02\n",
      " -1.74809117e-02  2.45068241e-02  4.05777320e-02 -2.78965128e-03\n",
      "  6.24729367e-03 -5.32612689e-02 -2.12666653e-02 -1.64216552e-02\n",
      "  2.95338221e-02  3.62383612e-02  4.33364883e-02  1.49895241e-02\n",
      "  1.22275120e-02  6.50088117e-03  1.90389995e-03  7.02047870e-02\n",
      " -4.94300015e-03 -2.93318881e-03 -5.26590794e-02  2.20450573e-02\n",
      "  6.42298674e-03  8.17860812e-02 -6.63384050e-02 -2.18314230e-02\n",
      "  2.28446582e-34  2.74173561e-02 -2.65210737e-02  2.09984127e-02\n",
      "  1.91366784e-02 -1.30122667e-03 -3.15869041e-02 -3.20651047e-02\n",
      "  2.66246889e-02  1.57008898e-02  1.38160298e-02 -5.86697124e-02]\n"
     ]
    }
   ],
   "source": [
    "## Defining the embedding model\n",
    "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "def job_embedding(job):\n",
    "    # Returns a saved value of the job embedding, or encodes it\n",
    "    ind = dict(enumerate(np.where(processed_data['job_title'] == job)[0])).get(0)\n",
    "    if encoded and ind != None:\n",
    "        return encoded_data['job_title'].loc[ind]\n",
    "    ind = dict(enumerate(np.where(processed_data['location'] == job)[0])).get(0)\n",
    "    if encoded and ind != None:\n",
    "        return encoded_data['location'].loc[ind]\n",
    "    encoding = model.encode(job, normalize_embeddings = True)\n",
    "    return encoding\n",
    "\n",
    "def encode_jobs():\n",
    "    # Encodes the preprocessed jobs and locations\n",
    "    encoded_jobs = np.array([job_embedding(job) for job in processed_jobs])\n",
    "    encoded_locations = np.array([job_embedding(loc) for loc in processed_locations])\n",
    "    data = np.concatenate((encoded_jobs, encoded_locations))\n",
    "    enc_samples = dict( [ (i, (data[i], data[i+len(processed_connections)], processed_connections[i], 0)) for i in range(len(connections)) ] )\n",
    "    encoded_data = pd.DataFrame.from_dict(enc_samples, orient = 'index', columns = ['job_title', 'location', 'log_connections', 'fit'])\n",
    "    return encoded_data\n",
    "\n",
    "encoded = False\n",
    "encoded_data = encode_jobs()\n",
    "encoded = True # Now all the data has been encoded\n",
    "encoded_example = encoded_data['job_title'][0]\n",
    "print('The first job title is encoded as:\\n', encoded_example)\n",
    "job_titles = dataframe['job_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df0919",
   "metadata": {},
   "source": [
    "Defining the way similar candidates are ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb935cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    # Returns the cosine similarity between vectors with norm == 1\n",
    "    norm1 = np.linalg.norm(vec1); norm2 = np.linalg.norm(vec2)\n",
    "    assert np.isclose(norm1,1); assert np.isclose(norm2,1)\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "def similar_jobs(job, location = None, connec = None, update = False):\n",
    "    # Returns a list of jobs most similar to 'job' based on their ranking\n",
    "    # If location is provided, it will be accounted for\n",
    "    # If connec is provided, it will be accounted for\n",
    "    # If update is set to True, dataframes will be sorted according to fitness\n",
    "    cosine_list = [] # Similarity ranking\n",
    "    if type(job) == str:\n",
    "        emb = job_embedding(job)\n",
    "    else:\n",
    "        emb = job # already encoded\n",
    "    if location != None:\n",
    "        emb += job_embedding(location) # account for location\n",
    "    if connec != None:\n",
    "        emb = np.concatenate((emb, [connec])) # account for connections\n",
    "    emb = np.array(normalize([emb])[0])\n",
    "    # Embedding of input job complete.\n",
    "    ## Next, go through all possible candidates\n",
    "    for i, tup in enumerate(zip(processed_jobs, processed_locations, processed_connections)):\n",
    "        job_, loc_, con_= tup\n",
    "        vec = job_embedding(job_) + (location!=None)*job_embedding(loc_)\n",
    "        if connec != None:\n",
    "            vec = np.concatenate((vec, [con_]))\n",
    "        vec = np.array(normalize([vec])[0])\n",
    "        cosine_list.append(cosine_similarity(emb, vec))\n",
    "    if update:\n",
    "        update_dataframe(cosine_list)\n",
    "    ranking = [[dataframe.index[i]] + dataframe.values[:10].tolist()[i] for i in range(10)]\n",
    "    return ranking\n",
    "\n",
    "def update_dataframe(cosine_list):\n",
    "    for i, cos in enumerate(cosine_list):\n",
    "        dataframe.loc[i, ['fit']] = cos\n",
    "        processed_data.loc[i, ['fit']] = cos\n",
    "        encoded_data.loc[i, ['fit']] = cos\n",
    "    dataframe.sort_values(by=['fit'], ascending = False, inplace = True)\n",
    "    processed_data.sort_values(by=['fit'], ascending = False, inplace = True)\n",
    "    encoded_data.sort_values(by=['fit'], ascending = False, inplace = True)\n",
    "    return None\n",
    "\n",
    "def star_rank(keyword, star = [], location = None, connec = None, weights = [0.4, 0.5, 0.1]):\n",
    "    # Returns a ranking based on keyword provided and starred candidates\n",
    "    # star is the list of job_title starred (string, exact match) (in chronological order)\n",
    "    key_emb = job_embedding(process_string(keyword))\n",
    "    key_w, star_w, prestar_w = weights # Importance accredited to keyword vs starred vs previously starred\n",
    "    if len(star) > 0:\n",
    "        star_emb = job_embedding(star.pop())\n",
    "        if len(star) > 0:\n",
    "            prestar_emb = np.average([job_embedding(s) for s in star], axis = 0)\n",
    "            prestar_emb = np.squeeze(normalize(prestar_emb.reshape(1,-1), axis = 1))\n",
    "            vec = key_w*key_emb + star_w*star_emb + prestar_w*prestar_emb\n",
    "        else:\n",
    "            vec = key_w*key_emb + star_w*star_emb\n",
    "    else:\n",
    "        vec = key_emb\n",
    "    # Now the vector vec is an amalgation of the embeddings of the keyword + starred candidates\n",
    "    vec = np.squeeze(normalize(vec.reshape(1,-1), axis = 1))\n",
    "    ranking = similar_jobs(vec, location = location, connec = connec, update = True)\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88e724",
   "metadata": {},
   "source": [
    "Below are the executive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a7665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ind = [] # List of indices of starred candidates\n",
    "\n",
    "def reset_starring():\n",
    "    # Removes all of the stars\n",
    "    star_ind = []\n",
    "    return None\n",
    "\n",
    "def star(ind):\n",
    "    # Stars the candidate by providing its index ind in the dataframe\n",
    "    star_ind.append(ind)\n",
    "    job, loc = dataframe['job_title'][ind], dataframe['location'][ind]\n",
    "    print('The candidate %s was starred with index %s'%((job, loc), ind))\n",
    "    return None\n",
    "\n",
    "def rank(keyword, location = None):\n",
    "    print('\\nThe keyword provided is: '+keyword)\n",
    "    processed_starred = [processed_jobs[ind] for ind in star_ind]\n",
    "    location, connec = None, None\n",
    "    if len(star_ind) > 0:\n",
    "        if location == None:\n",
    "            location = processed_locations[star_ind[-1]]\n",
    "        connec = processed_connections[star_ind[-1]]\n",
    "    ranking = star_rank(keyword, star = processed_starred.copy(), location = location, connec = connec)\n",
    "    print('\\nRanking with fit probability:\\n')\n",
    "    for ranked in ranking:\n",
    "        print(*zip(['index']+list(dataframe.columns), ranked))\n",
    "    print('\\nConsult the dataframe variable for the complete list\\n')\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9cd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_starring() ## This command clears any previous starring action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb52615",
   "metadata": {},
   "source": [
    "Below, the keyword can be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b28d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now providing the keywords\n",
    "keywords = ['Aspiring human resources',  'seeking human resources']\n",
    "keyword = keywords[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540bfd9",
   "metadata": {},
   "source": [
    "Below, a ranking based purely on the above-specified keyword is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b42377b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The keyword provided is: seeking human resources\n",
      "\n",
      "Ranking with fit probability:\n",
      "\n",
      "('index', 13) ('job_title', 'Seeking Human Resources Opportunities') ('location', 'Chicago, Illinois') ('connection', '390') ('fit', 0.8730392042023424)\n",
      "('index', 47) ('job_title', 'Seeking Human Resources Position') ('location', 'Las Vegas, Nevada Area') ('connection', '48') ('fit', 0.8367275564055341)\n",
      "('index', 49) ('job_title', 'Human Resources Generalist at Loparex') ('location', 'Raleigh-Durham, North Carolina Area') ('connection', '500+ ') ('fit', 0.6269668681912686)\n",
      "('index', 36) ('job_title', 'Human Resources Management Major') ('location', 'Milpitas, California') ('connection', '18') ('fit', 0.6180900576092362)\n",
      "('index', 48) ('job_title', 'Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis') ('location', 'Cape Girardeau, Missouri') ('connection', '103') ('fit', 0.612324722633486)\n",
      "('index', 22) ('job_title', 'Human Resources Professional') ('location', 'Greater Boston Area') ('connection', '16') ('fit', 0.5908161356945698)\n",
      "('index', 31) ('job_title', 'HR Manager at Endemol Shine North America') ('location', 'Los Angeles, California') ('connection', '268') ('fit', 0.5869571661191765)\n",
      "('index', 7) ('job_title', 'HR Senior Specialist') ('location', 'San Francisco Bay Area') ('connection', '500+ ') ('fit', 0.5836837123173678)\n",
      "('index', 26) ('job_title', \"Human Resources Generalist at Schwan's\") ('location', 'Amerika Birleşik Devletleri') ('connection', '500+ ') ('fit', 0.5816498837908421)\n",
      "('index', 8) ('job_title', 'Seeking Human Resources HRIS and Generalist Positions') ('location', 'Greater Philadelphia Area') ('connection', '500+ ') ('fit', 0.5770727559848622)\n",
      "\n",
      "Consult the dataframe variable for the complete list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_nostar = rank(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f818af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate (\"Human Resources Generalist at Schwan's\", 'Amerika Birleşik Devletleri') was starred with index 26\n"
     ]
    }
   ],
   "source": [
    "# Star a candidate\n",
    "star(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578d107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The keyword provided is: seeking human resources\n",
      "\n",
      "Ranking with fit probability:\n",
      "\n",
      "('index', 26) ('job_title', \"Human Resources Generalist at Schwan's\") ('location', 'Amerika Birleşik Devletleri') ('connection', '500+ ') ('fit', 0.9729696242938572)\n",
      "('index', 42) ('job_title', 'Seeking Human  Resources Opportunities. Open to travel and relocation.') ('location', 'Amerika Birleşik Devletleri') ('connection', '415') ('fit', 0.9338475852330026)\n",
      "('index', 7) ('job_title', 'HR Senior Specialist') ('location', 'San Francisco Bay Area') ('connection', '500+ ') ('fit', 0.7705070568104371)\n",
      "('index', 4) ('job_title', 'Advisory Board Member at Celal Bayar University') ('location', 'İzmir, Türkiye') ('connection', '500+ ') ('fit', 0.7705057298061428)\n",
      "('index', 6) ('job_title', 'Student at Humber College and Aspiring Human Resources Generalist') ('location', 'Kanada') ('connection', '61') ('fit', 0.7647589408817448)\n",
      "('index', 49) ('job_title', 'Human Resources Generalist at Loparex') ('location', 'Raleigh-Durham, North Carolina Area') ('connection', '500+ ') ('fit', 0.7571260606979093)\n",
      "('index', 27) ('job_title', 'Liberal Arts Major. Aspiring Human Resources Analyst.') ('location', 'Baton Rouge, Louisiana Area') ('connection', '7') ('fit', 0.7568595502640546)\n",
      "('index', 45) ('job_title', 'Aspiring Human Resources Professional') ('location', 'Kokomo, Indiana Area') ('connection', '71') ('fit', 0.7560673140514927)\n",
      "('index', 25) ('job_title', 'Human Resources|\\nConflict Management|\\nPolicies & Procedures|Talent Management|Benefits & Compensation') ('location', 'Dallas/Fort Worth Area') ('connection', '409') ('fit', 0.7499458787387288)\n",
      "('index', 16) ('job_title', 'Human Resources Specialist at Luxottica') ('location', 'Greater New York City Area') ('connection', '500+ ') ('fit', 0.7334296802578224)\n",
      "\n",
      "Consult the dataframe variable for the complete list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rank the candidates based on the keyword + starred candidate\n",
    "ranking = rank(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e26e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate ('Aspiring Human Resources Manager, seeking internship in Human Resources.', 'Houston, Texas Area') was starred with index 21\n"
     ]
    }
   ],
   "source": [
    "# Star another candidate\n",
    "star(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23fce033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The keyword provided is: seeking human resources\n",
      "\n",
      "Ranking with fit probability:\n",
      "\n",
      "('index', 21) ('job_title', 'Aspiring Human Resources Manager, seeking internship in Human Resources.') ('location', 'Houston, Texas Area') ('connection', '7') ('fit', 0.9352311482234041)\n",
      "('index', 12) ('job_title', 'Aspiring Human Resources Management student seeking an internship') ('location', 'Houston, Texas Area') ('connection', '500+ ') ('fit', 0.7680618076906078)\n",
      "('index', 10) ('job_title', 'SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR') ('location', 'Houston, Texas Area') ('connection', '500+ ') ('fit', 0.7619625080527194)\n",
      "('index', 23) ('job_title', 'Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621') ('location', 'San Jose, California') ('connection', '500+ ') ('fit', 0.7286836864880125)\n",
      "('index', 8) ('job_title', 'Seeking Human Resources HRIS and Generalist Positions') ('location', 'Greater Philadelphia Area') ('connection', '500+ ') ('fit', 0.7058109712382509)\n",
      "('index', 46) ('job_title', 'Student') ('location', 'Houston, Texas Area') ('connection', '4') ('fit', 0.6890590178900953)\n",
      "('index', 32) ('job_title', 'Human Resources professional for the world leader in GIS software') ('location', 'Highland, California') ('connection', '50') ('fit', 0.6849803905910785)\n",
      "('index', 33) ('job_title', 'RRP Brand Portfolio Executive at JTI (Japan Tobacco International)') ('location', 'Greater Philadelphia Area') ('connection', '500+ ') ('fit', 0.6753904160808768)\n",
      "('index', 30) ('job_title', 'Aspiring Human Resources Professional | An energetic and Team-Focused Leader') ('location', 'Austin, Texas Area') ('connection', '174') ('fit', 0.667951766499451)\n",
      "('index', 45) ('job_title', 'Aspiring Human Resources Professional') ('location', 'Kokomo, Indiana Area') ('connection', '71') ('fit', 0.6677120406470589)\n",
      "\n",
      "Consult the dataframe variable for the complete list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-rank based on the keyword + starred candidate (and learning from previously starred candidate(s))\n",
    "ranking = rank(keyword)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
